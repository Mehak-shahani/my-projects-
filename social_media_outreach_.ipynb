{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIrH2EjwWtCfULlwAp7d+x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mehak-shahani/my-projects-/blob/main/social_media_outreach_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzu0oxgj8Npm",
        "outputId": "c28b3344-6e9c-42b2-97f1-8a5d17831c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting apscheduler\n",
            "  Downloading APScheduler-3.11.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzlocal>=3.0 in /usr/local/lib/python3.11/dist-packages (from apscheduler) (5.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading APScheduler-3.11.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: apscheduler\n",
            "Successfully installed apscheduler-3.11.0\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install requests transformers pandas apscheduler\n",
        "\n",
        "# Import libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from apscheduler.schedulers.background import BackgroundScheduler\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Step 1: Define a function to fetch social media profile data\n",
        "def fetch_profiles():\n",
        "    # Simulated dataset (Replace this with LinkedIn or Twitter API data fetching)\n",
        "    profiles = [\n",
        "        {\"name\": \"John Doe\", \"profession\": \"Software Engineer\", \"interests\": [\"AI\", \"Machine Learning\"]},\n",
        "        {\"name\": \"Jane Smith\", \"profession\": \"Data Scientist\", \"interests\": [\"Big Data\", \"Visualization\"]},\n",
        "    ]\n",
        "    return pd.DataFrame(profiles)"
      ],
      "metadata": {
        "id": "5PpOhsq_8cse"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define a function for personalized message generation using NLP\n",
        "def generate_message(profile):\n",
        "    name = profile[\"name\"]\n",
        "    profession = profile[\"profession\"]\n",
        "    interests = \", \".join(profile[\"interests\"])\n",
        "    # Use a pre-trained model for message generation\n",
        "    generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "    message = generator(\n",
        "        f\"Hi {name}, I noticed you're a {profession} with interests in {interests}. I'd love to connect and discuss opportunities.\",\n",
        "        max_length=50,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "    return message[0][\"generated_text\"]\n"
      ],
      "metadata": {
        "id": "xOAm99O-8qRf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Automate follow-ups with a scheduler\n",
        "def schedule_follow_up(profile, delay_seconds):\n",
        "    # Schedule the follow-up message\n",
        "    def follow_up_message():\n",
        "        print(f\"Follow-up sent to {profile['name']}: Hope you got my last message!\")\n",
        "\n",
        "    follow_up_time = datetime.now() + timedelta(seconds=delay_seconds)\n",
        "    scheduler.add_job(follow_up_message, 'date', run_date=follow_up_time)\n",
        "    print(f\"Follow-up for {profile['name']} scheduled at {follow_up_time}\")"
      ],
      "metadata": {
        "id": "oURRGL79-Nir"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Main function to manage outreach\n",
        "def outreach_agent():\n",
        "    profiles = fetch_profiles()\n",
        "    for _, profile in profiles.iterrows():\n",
        "        message = generate_message(profile)\n",
        "        print(f\"Message to {profile['name']}: {message}\")\n",
        "        schedule_follow_up(profile, delay_seconds=30)  # Follow up after 30 seconds for demo\n",
        "\n",
        "# Initialize the scheduler\n",
        "scheduler = BackgroundScheduler()\n",
        "scheduler.start()\n",
        "\n",
        "# Run the agent\n",
        "outreach_agent()\n",
        "\n",
        "# Keep the script running to allow follow-ups to execute\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except (KeyboardInterrupt, SystemExit):\n",
        "    scheduler.shutdown()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtCIaEZZ-PvV",
        "outputId": "4490cdfd-ecd0-4228-bff9-e3c082d2a581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message to John Doe: Hi John Doe, I noticed you're a Software Engineer with interests in AI, Machine Learning. I'd love to connect and discuss opportunities. Can you do any specific job in AI or Machine Learning?\"\n",
            "\n",
            "John Doe: I'd love to connect\n",
            "Follow-up for John Doe scheduled at 2025-01-28 12:53:59.902098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message to Jane Smith: Hi Jane Smith, I noticed you're a Data Scientist with interests in Big Data, Visualization. I'd love to connect and discuss opportunities.\n",
            "\n",
            "Johanna Smith: Well, Data Science is really hard if you're not familiar with it\n",
            "Follow-up for Jane Smith scheduled at 2025-01-28 12:54:02.547635\n",
            "Follow-up sent to John Doe: Hope you got my last message!\n",
            "Follow-up sent to Jane Smith: Hope you got my last message!\n"
          ]
        }
      ]
    }
  ]
}